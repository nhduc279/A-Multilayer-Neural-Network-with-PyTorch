{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(type='cuda')\n",
    "else:\n",
    "    device = torch.device(type='cpu')\n",
    "    \n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 279\n",
    "\n",
    "def seed_everything(seed=RANDOM_SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = ['TV', 'Newspaper', 'Radio']\n",
    "X = df[features]\n",
    "y = df['Sales']\n",
    "\n",
    "# scaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train-test-split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=279)\n",
    "\n",
    "X_train = torch.tensor(sc.fit_transform(X_train.values), \n",
    "                       device=device, \n",
    "                       dtype=torch.float)\n",
    "\n",
    "y_train = torch.tensor(y_train.values, \n",
    "                       device=device,\n",
    "                       dtype=torch.float)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train.numpy(),\n",
    "                                                  y_train.numpy(),\n",
    "                                                  test_size=0.05,\n",
    "                                                  random_state=1)\n",
    "\n",
    "X_val = torch.tensor(X_val, device=device, dtype=torch.float)\n",
    "y_val = torch.tensor(y_val, device=device, dtype=torch.float)\n",
    "\n",
    "X_train = torch.tensor(X_train, device=device, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.float)\n",
    "\n",
    "X_test = torch.tensor(sc.transform(X_test.values), device=device, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test.values, device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a multi-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.my_netwrok = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_features, 128),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(128, 96),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(96, 64),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.my_netwrok(x).view(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cost, val_cost = [], []\n",
    "\n",
    "def train(model, x, y, x_val, y_val, learning_rate=0.005, num_epochs=10, seed=279, minibatch_size=32):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for e in trange(num_epochs):\n",
    "        print(f'Epoch: {e+1}', end='')\n",
    "        shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "        minibatches = torch.split(shuffle_idx, minibatch_size)\n",
    "\n",
    "        for minibatch_idx in minibatches:\n",
    "            if minibatch_idx.shape[0] == 32:\n",
    "                yhat = model.forward(x[minibatch_idx])\n",
    "                loss = F.mse_loss(yhat, y[minibatch_idx])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            yhat = model.forward(x)\n",
    "            curr_loss = F.mse_loss(y, yhat)\n",
    "            yhat_val = model.forward(x_val)\n",
    "            curr_loss_val = F.mse_loss(y_val, yhat_val)\n",
    "            train_cost.append(curr_loss)\n",
    "            val_cost.append(curr_loss_val)\n",
    "            print(f' | Train loss: {curr_loss:.3f}' , end='')\n",
    "            print(f' | Val loss: {curr_loss_val:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNetwork(\n",
       "  (my_netwrok): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=96, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=96, out_features=64, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): SiLU()\n",
       "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (11): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNetwork(num_features=X_train.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770af5e661804155bfdf635558da8d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss: 218.909 | Val loss: 173.515\n",
      "Epoch: 2 | Train loss: 191.277 | Val loss: 148.427\n",
      "Epoch: 3 | Train loss: 101.664 | Val loss: 70.684\n",
      "Epoch: 4 | Train loss: 24.875 | Val loss: 27.160\n",
      "Epoch: 5 | Train loss: 7.871 | Val loss: 6.886\n",
      "Epoch: 6 | Train loss: 18.034 | Val loss: 12.678\n",
      "Epoch: 7 | Train loss: 10.313 | Val loss: 6.774\n",
      "Epoch: 8 | Train loss: 6.484 | Val loss: 5.532\n",
      "Epoch: 9 | Train loss: 2.629 | Val loss: 4.777\n",
      "Epoch: 10 | Train loss: 3.553 | Val loss: 1.157\n",
      "Epoch: 11 | Train loss: 2.302 | Val loss: 0.994\n",
      "Epoch: 12 | Train loss: 1.974 | Val loss: 2.467\n",
      "Epoch: 13 | Train loss: 0.853 | Val loss: 0.237\n",
      "Epoch: 14 | Train loss: 0.929 | Val loss: 0.604\n",
      "Epoch: 15 | Train loss: 0.737 | Val loss: 0.309\n",
      "Epoch: 16 | Train loss: 0.412 | Val loss: 0.411\n",
      "Epoch: 17 | Train loss: 0.426 | Val loss: 0.754\n",
      "Epoch: 18 | Train loss: 0.360 | Val loss: 0.926\n",
      "Epoch: 19 | Train loss: 0.348 | Val loss: 1.350\n",
      "Epoch: 20 | Train loss: 0.329 | Val loss: 1.253\n",
      "Epoch: 21 | Train loss: 0.326 | Val loss: 1.104\n",
      "Epoch: 22 | Train loss: 0.304 | Val loss: 0.784\n",
      "Epoch: 23 | Train loss: 0.269 | Val loss: 0.811\n",
      "Epoch: 24 | Train loss: 0.270 | Val loss: 0.865\n",
      "Epoch: 25 | Train loss: 0.255 | Val loss: 0.775\n",
      "Epoch: 26 | Train loss: 0.252 | Val loss: 0.515\n",
      "Epoch: 27 | Train loss: 0.244 | Val loss: 0.654\n",
      "Epoch: 28 | Train loss: 0.235 | Val loss: 0.770\n",
      "Epoch: 29 | Train loss: 0.227 | Val loss: 0.478\n",
      "Epoch: 30 | Train loss: 0.239 | Val loss: 0.311\n",
      "Epoch: 31 | Train loss: 0.217 | Val loss: 0.333\n",
      "Epoch: 32 | Train loss: 0.211 | Val loss: 0.486\n",
      "Epoch: 33 | Train loss: 0.199 | Val loss: 0.532\n",
      "Epoch: 34 | Train loss: 0.191 | Val loss: 0.474\n",
      "Epoch: 35 | Train loss: 0.183 | Val loss: 0.565\n",
      "Epoch: 36 | Train loss: 0.187 | Val loss: 0.759\n",
      "Epoch: 37 | Train loss: 0.177 | Val loss: 0.549\n",
      "Epoch: 38 | Train loss: 0.172 | Val loss: 0.305\n",
      "Epoch: 39 | Train loss: 0.160 | Val loss: 0.296\n",
      "Epoch: 40 | Train loss: 0.175 | Val loss: 0.479\n",
      "Epoch: 41 | Train loss: 0.148 | Val loss: 0.405\n",
      "Epoch: 42 | Train loss: 0.144 | Val loss: 0.394\n",
      "Epoch: 43 | Train loss: 0.138 | Val loss: 0.237\n",
      "Epoch: 44 | Train loss: 0.147 | Val loss: 0.304\n",
      "Epoch: 45 | Train loss: 0.132 | Val loss: 0.267\n",
      "Epoch: 46 | Train loss: 0.130 | Val loss: 0.183\n",
      "Epoch: 47 | Train loss: 0.116 | Val loss: 0.235\n",
      "Epoch: 48 | Train loss: 0.127 | Val loss: 0.211\n",
      "Epoch: 49 | Train loss: 0.129 | Val loss: 0.153\n",
      "Epoch: 50 | Train loss: 0.124 | Val loss: 0.218\n",
      "Epoch: 51 | Train loss: 0.111 | Val loss: 0.116\n",
      "Epoch: 52 | Train loss: 0.128 | Val loss: 0.094\n",
      "Epoch: 53 | Train loss: 0.138 | Val loss: 0.213\n",
      "Epoch: 54 | Train loss: 0.112 | Val loss: 0.118\n",
      "Epoch: 55 | Train loss: 0.110 | Val loss: 0.199\n",
      "Epoch: 56 | Train loss: 0.102 | Val loss: 0.125\n",
      "Epoch: 57 | Train loss: 0.104 | Val loss: 0.099\n",
      "Epoch: 58 | Train loss: 0.105 | Val loss: 0.111\n",
      "Epoch: 59 | Train loss: 0.098 | Val loss: 0.104\n",
      "Epoch: 60 | Train loss: 0.093 | Val loss: 0.092\n",
      "Epoch: 61 | Train loss: 0.094 | Val loss: 0.100\n",
      "Epoch: 62 | Train loss: 0.097 | Val loss: 0.088\n",
      "Epoch: 63 | Train loss: 0.089 | Val loss: 0.084\n",
      "Epoch: 64 | Train loss: 0.089 | Val loss: 0.081\n",
      "Epoch: 65 | Train loss: 0.089 | Val loss: 0.078\n",
      "Epoch: 66 | Train loss: 0.087 | Val loss: 0.085\n",
      "Epoch: 67 | Train loss: 0.088 | Val loss: 0.089\n",
      "Epoch: 68 | Train loss: 0.094 | Val loss: 0.078\n",
      "Epoch: 69 | Train loss: 0.102 | Val loss: 0.074\n",
      "Epoch: 70 | Train loss: 0.132 | Val loss: 0.135\n",
      "Epoch: 71 | Train loss: 0.106 | Val loss: 0.073\n",
      "Epoch: 72 | Train loss: 0.094 | Val loss: 0.077\n",
      "Epoch: 73 | Train loss: 0.087 | Val loss: 0.077\n",
      "Epoch: 74 | Train loss: 0.091 | Val loss: 0.095\n",
      "Epoch: 75 | Train loss: 0.095 | Val loss: 0.074\n",
      "Epoch: 76 | Train loss: 0.096 | Val loss: 0.073\n",
      "Epoch: 77 | Train loss: 0.088 | Val loss: 0.078\n",
      "Epoch: 78 | Train loss: 0.086 | Val loss: 0.082\n",
      "Epoch: 79 | Train loss: 0.089 | Val loss: 0.080\n",
      "Epoch: 80 | Train loss: 0.085 | Val loss: 0.082\n",
      "Epoch: 81 | Train loss: 0.089 | Val loss: 0.077\n",
      "Epoch: 82 | Train loss: 0.098 | Val loss: 0.083\n",
      "Epoch: 83 | Train loss: 0.123 | Val loss: 0.080\n",
      "Epoch: 84 | Train loss: 0.112 | Val loss: 0.114\n",
      "Epoch: 85 | Train loss: 0.105 | Val loss: 0.104\n",
      "Epoch: 86 | Train loss: 0.161 | Val loss: 0.068\n",
      "Epoch: 87 | Train loss: 0.249 | Val loss: 0.225\n",
      "Epoch: 88 | Train loss: 0.182 | Val loss: 0.084\n",
      "Epoch: 89 | Train loss: 0.237 | Val loss: 0.073\n",
      "Epoch: 90 | Train loss: 0.231 | Val loss: 0.301\n",
      "Epoch: 91 | Train loss: 0.120 | Val loss: 0.071\n",
      "Epoch: 92 | Train loss: 0.100 | Val loss: 0.129\n",
      "Epoch: 93 | Train loss: 0.143 | Val loss: 0.263\n",
      "Epoch: 94 | Train loss: 0.124 | Val loss: 0.112\n",
      "Epoch: 95 | Train loss: 0.092 | Val loss: 0.105\n",
      "Epoch: 96 | Train loss: 0.108 | Val loss: 0.159\n",
      "Epoch: 97 | Train loss: 0.097 | Val loss: 0.090\n",
      "Epoch: 98 | Train loss: 0.089 | Val loss: 0.116\n",
      "Epoch: 99 | Train loss: 0.085 | Val loss: 0.093\n",
      "Epoch: 100 | Train loss: 0.086 | Val loss: 0.088\n"
     ]
    }
   ],
   "source": [
    "train(model, \n",
    "      X_train, y_train,\n",
    "      X_val, y_val, \n",
    "      num_epochs=100,\n",
    "      learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_cost)), train_cost)\n",
    "plt.plot(range(len(val_cost)), val_cost)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE-Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1995, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(model.forward(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network that I designed (MSE = 0.1995) outperforms RandomForest (MSE = 0.385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
